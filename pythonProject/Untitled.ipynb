{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc1217af-3bc7-48d0-9c0e-7ad8ef86d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave, struct, os\n",
    "from openai import OpenAI\n",
    "from pvrecorder import PvRecorder\n",
    "from playsound import playsound\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1f35cf-b8ca-4ead-bd60-b306811283c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b5dc5d-2252-41f0-bf07-7e1a96c0e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a455d686-2cb2-45bd-b07c-f88c38ef2119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9K4RWzk7ihSxOJeQz9HluumS3qlMM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm your friendly neighborhood joke-telling assistant! But don't worry, I won't quit my day job.\", role='assistant', function_call=None, tool_calls=None))], created=1714570666, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3b956da36b', usage=CompletionUsage(completion_tokens=23, prompt_tokens=28, total_tokens=51))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d36d8cdf-6fa8-4950-8cbc-8207dab0678f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an AI assistant designed to help with answering questions and providing information. I am knowledgeable in a variety of academic topics and can assist with research, writing, and general queries. How can I assist you today?'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f50b9664-25d2-432a-8dbb-295dcbdb44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.context = [\n",
    "            {\"role\" : \"system\", \"content\":\"You are a witty assistant, always answering with a Joke.\"},\n",
    "        ]\n",
    "\n",
    "    def chat(self, message):\n",
    "        self.context.append(\n",
    "            {\"role\" : \"user\", \"content\" : message}\n",
    "        )\n",
    "        response = self.client.chat.completions.create(\n",
    "            model = \"gpt-3.5-turbo\",\n",
    "            messages = self.context\n",
    "        )\n",
    "        response_content = response.choices[0].message.content\n",
    "        self.context.append(\n",
    "            {\"role\": \"assistant\", \"content\": response_content}\n",
    "        )\n",
    "        self.print_chat()\n",
    "        self.speak(response_content)\n",
    "\n",
    "    def print_chat(self):\n",
    "        for message in self.context:\n",
    "            if message[\"role\"] == \"user\":\n",
    "                print(f'USER: {message[\"content\"]}')\n",
    "            elif message[\"role\"] == \"assistant\":\n",
    "                print(f'BOT: {message[\"content\"]}')\n",
    "\n",
    "# Make Chatbot speak\n",
    "    def speak(self, message, index=0):\n",
    "        speech_file_path = os.getcwd() + f\"/speech_{index}.mp3\"\n",
    "        # 같은 파일 생성하지 않게 만들기\n",
    "        while os.path.exists(speech_file_path):\n",
    "            index += 1\n",
    "            speech_file_path = os.getcwd() + f\"/speech_{index}.mp3\"\n",
    "        try:\n",
    "            response = self.client.audio.speech.create(\n",
    "                model=\"tts-1-hd\",\n",
    "                voice=\"echo\",\n",
    "                input=message\n",
    "            )\n",
    "            with open(speech_file_path, mode=\"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            playsound(speech_file_path)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred while creating speech:\", e)\n",
    "\n",
    "# To Record Audio\n",
    "    def record_audio(self, index=0):\n",
    "        recorder = PvRecorder(device_index=-1, frame_length=512)\n",
    "        audio = []\n",
    "        filepath = os.getcwd() + f\"/recorded_{index}.mp3\"\n",
    "        \n",
    "        try:\n",
    "            recorder.start()\n",
    "            print(\"Audio recording started ...\")\n",
    "            while True:\n",
    "                frame = recorder.read()\n",
    "                audio.extend(frame)\n",
    "        except KeyboardInterrupt:\n",
    "            recorder.stop()\n",
    "            print(\"Audio recording stopped ...\")\n",
    "            with wave.open(filepath, 'w') as f:\n",
    "                f.setparams((1, 2, 16000, 512, \"NONE\", \"NONE\"))\n",
    "                f.writeframes(struct.pack(\"h\" * len(audio), *audio))\n",
    "        finally:\n",
    "            recorder.delete()\n",
    "            return filepath                 \n",
    "\n",
    "# Transcribe\n",
    "    def transcribe(self, audio_path):\n",
    "        audio_file= open(audio_path, \"rb\")\n",
    "        transcript = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file\n",
    "        )\n",
    "        return transcript.text\n",
    "\n",
    "# Voice Chat\n",
    "    def voicechat(self):\n",
    "        recorded_filepath = self.record_audio(index=len(self.context))\n",
    "        message = self.transcribe(recorded_filepath)\n",
    "        self.chat(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9210337-d7d9-48e6-a950-8283747632f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = Chatbot(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f695cd7e-78ae-4303-ad6d-6485b8f375b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER: Hello, who are you?\n",
      "BOT: I'm your trusty virtual assistant here to serve up some pun-tastic jokes!\n"
     ]
    }
   ],
   "source": [
    "chatbot.chat(\"Hello, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a81f72ae-5357-4fc6-8f77-499a9936e6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio recording started ...\n",
      "Audio recording stopped ...\n",
      "USER: 오늘 어떻게 지냈어요?\n",
      "BOT: 왜요, 제 얼굴이 그렇게 심각하게 보이나요?\n"
     ]
    }
   ],
   "source": [
    "chatbot.voicechat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28b7f8be-3015-4021-a908-53c3741cf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder = PvRecorder(device_index=-1, frame_length=512)\n",
    "audio = []\n",
    "path = 'audio_recording.wav'\n",
    "\n",
    "try:\n",
    "    recorder.start()\n",
    "    while True:\n",
    "        frame = recorder.read()\n",
    "        audio.extend(frame)\n",
    "except KeyboardInterrupt:\n",
    "    recorder.stop()\n",
    "    with wave.open(path, 'w') as f:\n",
    "        f.setparams((1, 2, 16000, 512, \"NONE\", \"NONE\"))\n",
    "        f.writeframes(struct.pack(\"h\" * len(audio), *audio))\n",
    "finally:\n",
    "    recorder.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb0b1d-2155-4eb3-8134-0e8e95964ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = open(path, \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file\n",
    ")\n",
    "transcript"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
